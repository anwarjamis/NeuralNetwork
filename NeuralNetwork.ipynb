{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetwork.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq9IqBvXO37j"
      },
      "source": [
        "*Para efectos de Google Colab, primero se deben cargar todos los archivos de la carpeta MNIST por separado, luego crear las dos carpetas (processed y raw) y agregar los archivos correspondientes a cada carpeta para finalmente crear una nueva carpeta llamada MNIST donde se deben agregar las dos carpetas anteriormente mencionadas con los archivos correspondientes a cada carpeta antes de iniciar. Además se deben correr todas las casillas de código en orden para obtener los resultados correctamente.*\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbhjOz3MP1jE"
      },
      "source": [
        "Primero importamos las librerías para el desarrollo de cada ejercicio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQc_4WK1l2rx"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tRdLXmRP7Ir"
      },
      "source": [
        "Luego implementamos la función entregada en main.py para calcular la precisión del conjunto de testeo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H2epqkgl7Nw"
      },
      "source": [
        "# Funcion que calcula la precision sobre el conjunto de testeo  \n",
        "def calculateAccuracy(model, test_loader):\n",
        "      \n",
        "  correct = 0\n",
        "  total = 0\n",
        "  # Iteramos por el conjunto de testeo\n",
        "  for images, labels in test_loader:\n",
        "    # Transformamos imagenes a vectores\n",
        "    images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "    # Pasada forward\n",
        "    outputs = model(images)\n",
        "\n",
        "    # Obtenemos la prediccion de la red: la clase con mayor valor\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    # numero total de labels en el batch\n",
        "    total += labels.size(0)\n",
        "\n",
        "    # total predicciones correctas\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "  accuracy = 100 * correct / total\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ea7SB6VQGeq"
      },
      "source": [
        "Aquí es donde se implementa la clase solicitada. El procedimiento de como se implementa esta detallada en los comentarios del código."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNv3Jj1qmBtB"
      },
      "source": [
        "class FFNN_1HL(torch.nn.Module):   #creamos la clase\n",
        "  def __init__(self, input_dim, hidden1_dim, output_dim): #definimos el constructor de la clase\n",
        "    super(FFNN_1HL, self).__init__()\n",
        "    self.fc1 = torch.nn.Linear(input_dim, hidden1_dim, bias=True) #inicializa capa de entrada y una capa oculta\n",
        "    self.act1 = torch.nn.ReLU() #se asigna la funcion de activación ReLU\n",
        "    self.fc2 = torch.nn.Linear(hidden1_dim, output_dim, bias=True) #inicializa la capa de salida\n",
        "\n",
        "  def forward(self, x): #definir funcion forward\n",
        "    z1 = self.fc1(x)\n",
        "    h1 = self.act1(z1)\n",
        "    z = self.fc2(h1) # No aplicamos softmax, ya que la funcion torch.nn.CrossEntropyLoss() la aplica\n",
        "    return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y06l0mt6Q6qP"
      },
      "source": [
        "Luego aplicamos la clase creada a cada ejemplo solicitado. Los análisis entre los casos se encuentran detallados en el informe entregado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N97REwZbRIfk"
      },
      "source": [
        "Se entrena y prueba el modelo con descenso estocástico por gradiente simple, tasa de aprendizaje de 0.01 y dimensión de la capa oculta igual a 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVaWoj6illNT",
        "outputId": "94bbbe8b-a3bf-4805-bcef-a4d0ee1a579c"
      },
      "source": [
        "#Entrenamiento y prueba de la red con el dataset MNIST\n",
        "\n",
        "#Código para cargar los datos\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor())\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "batch_size = 32  # No cambiar tamaño del batch\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "########################################\n",
        "# Construimos la red\n",
        "# Las dimensiones de entrada y salida corresponden al dataset MNIST\n",
        "\n",
        "input_dim = 28*28\n",
        "hidden_dim = 1\n",
        "output_dim = 10\n",
        "\n",
        "model = FFNN_1HL(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "###############################\n",
        "# Definimos la funcion de perdida, en este caso entropia cruzada\n",
        "# Ojo: esta funcion calcula softmax y luego la entropia cruzada vista en clases\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "###################\n",
        "#Definimos el algoritmo de optimizacion, en este caso stochastic gradient descent simple\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "## Utilizar otros optimizers cuando sea necesario\n",
        "\n",
        "####################\n",
        "# Entrenamos y testeamos la red. No es necesario cambiar este código.\n",
        "# Imprimimos la precision antes de comenzar, la precision y funcion de perdida despues de cada epoca,\n",
        "# y el tiempo total de entrenamiento\n",
        "\n",
        "num_epochs = 10  # No cambiar cantidad de epocas\n",
        "\n",
        "accuracy = calculateAccuracy(model, test_loader)\n",
        "print('Initial Accuracy: {}'.format(accuracy))\n",
        "\n",
        "tiempo_epochs = 0\n",
        "for epoch in range(num_epochs):\n",
        "    inicio_epoch = time.process_time()\n",
        "    for images, labels in train_loader:\n",
        "        # Transformamos imagenes a vectores \n",
        "        images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "        # Pasada forward\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculamos la pérdida\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        # Hacemos la pasada backward\n",
        "        # Esto rellena el atributo .grad de todos los parametros\n",
        "        loss.backward()\n",
        "\n",
        "        # Hacemos un paso en el algoritmo de optimizacion\n",
        "        optimizer.step()\n",
        "\n",
        "        # Inicializamos los gradientes de los parametros a 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    tiempo_epochs += time.process_time() - inicio_epoch\n",
        "    ###############################\n",
        "    # calculamos la precision sobre el conjunto de testeo        \n",
        "    accuracy = calculateAccuracy(model, test_loader)\n",
        "    \n",
        "\n",
        "    # Reporte\n",
        "    #print('Epoch: {}. Loss: {}'.format(epoch, loss.item()))\n",
        "    print('Epoch: {}. Loss: {}. Accuracy: {}'.format(epoch, loss.item(), accuracy))\n",
        "\n",
        "print('Total time: {}'.format(tiempo_epochs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Accuracy: 8.920000076293945\n",
            "Epoch: 0. Loss: 2.04119610786438. Accuracy: 21.649999618530273\n",
            "Epoch: 1. Loss: 1.8716106414794922. Accuracy: 21.510000228881836\n",
            "Epoch: 2. Loss: 1.7473570108413696. Accuracy: 25.43000030517578\n",
            "Epoch: 3. Loss: 1.833014726638794. Accuracy: 22.959999084472656\n",
            "Epoch: 4. Loss: 1.6823080778121948. Accuracy: 29.709999084472656\n",
            "Epoch: 5. Loss: 1.8993515968322754. Accuracy: 31.5\n",
            "Epoch: 6. Loss: 1.7012053728103638. Accuracy: 32.2400016784668\n",
            "Epoch: 7. Loss: 1.737265706062317. Accuracy: 32.2599983215332\n",
            "Epoch: 8. Loss: 1.6939116716384888. Accuracy: 32.540000915527344\n",
            "Epoch: 9. Loss: 1.7451506853103638. Accuracy: 30.5\n",
            "Total time: 59.683837499999925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLjMoCSCRdnC"
      },
      "source": [
        "Se entrena y prueba el modelo con descenso estocástico por gradiente simple, tasa de aprendizaje de 0.01 y dimensión de la capa oculta igual a 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kilhe3tvENKp",
        "outputId": "d6cd01c2-e520-4397-9305-5b245e1a91a1"
      },
      "source": [
        "#Entrenamiento y prueba de la red con el dataset MNIST\n",
        "\n",
        "#Código para cargar los datos\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor())\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "batch_size = 32  # No cambiar tamaño del batch\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "########################################\n",
        "# Construimos la red\n",
        "# Las dimensiones de entrada y salida corresponden al dataset MNIST\n",
        "\n",
        "input_dim = 28*28\n",
        "hidden_dim = 10\n",
        "output_dim = 10\n",
        "\n",
        "model = FFNN_1HL(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "###############################\n",
        "# Definimos la funcion de perdida, en este caso entropia cruzada\n",
        "# Ojo: esta funcion calcula softmax y luego la entropia cruzada vista en clases\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "###################\n",
        "#Definimos el algoritmo de optimizacion, en este caso stochastic gradient descent simple\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "## Utilizar otros optimizers cuando sea necesario\n",
        "\n",
        "####################\n",
        "# Entrenamos y testeamos la red. No es necesario cambiar este código.\n",
        "# Imprimimos la precision antes de comenzar, la precision y funcion de perdida despues de cada epoca,\n",
        "# y el tiempo total de entrenamiento\n",
        "\n",
        "num_epochs = 10  # No cambiar cantidad de epocas\n",
        "\n",
        "accuracy = calculateAccuracy(model, test_loader)\n",
        "print('Initial Accuracy: {}'.format(accuracy))\n",
        "\n",
        "tiempo_epochs = 0\n",
        "for epoch in range(num_epochs):\n",
        "    inicio_epoch = time.process_time()\n",
        "    for images, labels in train_loader:\n",
        "        # Transformamos imagenes a vectores \n",
        "        images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "        # Pasada forward\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculamos la pérdida\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        # Hacemos la pasada backward\n",
        "        # Esto rellena el atributo .grad de todos los parametros\n",
        "        loss.backward()\n",
        "\n",
        "        # Hacemos un paso en el algoritmo de optimizacion\n",
        "        optimizer.step()\n",
        "\n",
        "        # Inicializamos los gradientes de los parametros a 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    tiempo_epochs += time.process_time() - inicio_epoch\n",
        "    ###############################\n",
        "    # calculamos la precision sobre el conjunto de testeo        \n",
        "    accuracy = calculateAccuracy(model, test_loader)\n",
        "    \n",
        "\n",
        "    # Reporte\n",
        "    #print('Epoch: {}. Loss: {}'.format(epoch, loss.item()))\n",
        "    print('Epoch: {}. Loss: {}. Accuracy: {}'.format(epoch, loss.item(), accuracy))\n",
        "\n",
        "print('Total time: {}'.format(tiempo_epochs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Accuracy: 9.65999984741211\n",
            "Epoch: 0. Loss: 0.4459160268306732. Accuracy: 88.37999725341797\n",
            "Epoch: 1. Loss: 0.28712576627731323. Accuracy: 90.18000030517578\n",
            "Epoch: 2. Loss: 0.4649253189563751. Accuracy: 91.16000366210938\n",
            "Epoch: 3. Loss: 0.3090496063232422. Accuracy: 91.62000274658203\n",
            "Epoch: 4. Loss: 0.3345477879047394. Accuracy: 91.87000274658203\n",
            "Epoch: 5. Loss: 0.2712971568107605. Accuracy: 92.13999938964844\n",
            "Epoch: 6. Loss: 0.32752951979637146. Accuracy: 92.02999877929688\n",
            "Epoch: 7. Loss: 0.1763847917318344. Accuracy: 92.41000366210938\n",
            "Epoch: 8. Loss: 0.07958599179983139. Accuracy: 92.37999725341797\n",
            "Epoch: 9. Loss: 0.1716882288455963. Accuracy: 92.55999755859375\n",
            "Total time: 60.809273859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU9xQQEERgvy"
      },
      "source": [
        "Se entrena y prueba el modelo con descenso estocástico por gradiente simple, tasa de aprendizaje de 0.01 y dimensión de la capa oculta igual a 100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwBwlJZIEi2u",
        "outputId": "29c73636-9e28-4965-96c8-9e1ef05ab62a"
      },
      "source": [
        "#Entrenamiento y prueba de la red con el dataset MNIST\n",
        "\n",
        "#Código para cargar los datos\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor())\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "batch_size = 32  # No cambiar tamaño del batch\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "########################################\n",
        "# Construimos la red\n",
        "# Las dimensiones de entrada y salida corresponden al dataset MNIST\n",
        "\n",
        "input_dim = 28*28\n",
        "hidden_dim = 100\n",
        "output_dim = 10\n",
        "\n",
        "model = FFNN_1HL(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "###############################\n",
        "# Definimos la funcion de perdida, en este caso entropia cruzada\n",
        "# Ojo: esta funcion calcula softmax y luego la entropia cruzada vista en clases\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "###################\n",
        "#Definimos el algoritmo de optimizacion, en este caso stochastic gradient descent simple\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "## Utilizar otros optimizers cuando sea necesario\n",
        "\n",
        "####################\n",
        "# Entrenamos y testeamos la red. No es necesario cambiar este código.\n",
        "# Imprimimos la precision antes de comenzar, la precision y funcion de perdida despues de cada epoca,\n",
        "# y el tiempo total de entrenamiento\n",
        "\n",
        "num_epochs = 10  # No cambiar cantidad de epocas\n",
        "\n",
        "accuracy = calculateAccuracy(model, test_loader)\n",
        "print('Initial Accuracy: {}'.format(accuracy))\n",
        "\n",
        "tiempo_epochs = 0\n",
        "for epoch in range(num_epochs):\n",
        "    inicio_epoch = time.process_time()\n",
        "    for images, labels in train_loader:\n",
        "        # Transformamos imagenes a vectores \n",
        "        images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "        # Pasada forward\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculamos la pérdida\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        # Hacemos la pasada backward\n",
        "        # Esto rellena el atributo .grad de todos los parametros\n",
        "        loss.backward()\n",
        "\n",
        "        # Hacemos un paso en el algoritmo de optimizacion\n",
        "        optimizer.step()\n",
        "\n",
        "        # Inicializamos los gradientes de los parametros a 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    tiempo_epochs += time.process_time() - inicio_epoch\n",
        "    ###############################\n",
        "    # calculamos la precision sobre el conjunto de testeo        \n",
        "    accuracy = calculateAccuracy(model, test_loader)\n",
        "    \n",
        "\n",
        "    # Reporte\n",
        "    #print('Epoch: {}. Loss: {}'.format(epoch, loss.item()))\n",
        "    print('Epoch: {}. Loss: {}. Accuracy: {}'.format(epoch, loss.item(), accuracy))\n",
        "\n",
        "print('Total time: {}'.format(tiempo_epochs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Accuracy: 12.069999694824219\n",
            "Epoch: 0. Loss: 0.3579598069190979. Accuracy: 89.58000183105469\n",
            "Epoch: 1. Loss: 0.5179370045661926. Accuracy: 90.81999969482422\n",
            "Epoch: 2. Loss: 0.5793843865394592. Accuracy: 91.87000274658203\n",
            "Epoch: 3. Loss: 0.17780552804470062. Accuracy: 92.30999755859375\n",
            "Epoch: 4. Loss: 0.1683051586151123. Accuracy: 92.87000274658203\n",
            "Epoch: 5. Loss: 0.05440385267138481. Accuracy: 93.33999633789062\n",
            "Epoch: 6. Loss: 0.1325538009405136. Accuracy: 93.56999969482422\n",
            "Epoch: 7. Loss: 0.19975878298282623. Accuracy: 93.91000366210938\n",
            "Epoch: 8. Loss: 0.10683401674032211. Accuracy: 94.27999877929688\n",
            "Epoch: 9. Loss: 0.09696470946073532. Accuracy: 94.38999938964844\n",
            "Total time: 71.03732909000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CbWLDs0Ri-8"
      },
      "source": [
        "Se entrena y prueba el modelo con descenso estocástico por gradiente simple, tasa de aprendizaje de 0.01 y dimensión de la capa oculta igual a 200."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmIKF2pZErhY",
        "outputId": "634a93e2-d7a5-4304-f538-f99201f96d9c"
      },
      "source": [
        "#Entrenamiento y prueba de la red con el dataset MNIST\n",
        "\n",
        "#Código para cargar los datos\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor())\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "batch_size = 32  # No cambiar tamaño del batch\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "########################################\n",
        "# Construimos la red\n",
        "# Las dimensiones de entrada y salida corresponden al dataset MNIST\n",
        "\n",
        "input_dim = 28*28\n",
        "hidden_dim = 200\n",
        "output_dim = 10\n",
        "\n",
        "model = FFNN_1HL(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "###############################\n",
        "# Definimos la funcion de perdida, en este caso entropia cruzada\n",
        "# Ojo: esta funcion calcula softmax y luego la entropia cruzada vista en clases\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "###################\n",
        "#Definimos el algoritmo de optimizacion, en este caso stochastic gradient descent simple\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "## Utilizar otros optimizers cuando sea necesario\n",
        "\n",
        "####################\n",
        "# Entrenamos y testeamos la red. No es necesario cambiar este código.\n",
        "# Imprimimos la precision antes de comenzar, la precision y funcion de perdida despues de cada epoca,\n",
        "# y el tiempo total de entrenamiento\n",
        "\n",
        "num_epochs = 10  # No cambiar cantidad de epocas\n",
        "\n",
        "accuracy = calculateAccuracy(model, test_loader)\n",
        "print('Initial Accuracy: {}'.format(accuracy))\n",
        "\n",
        "tiempo_epochs = 0\n",
        "for epoch in range(num_epochs):\n",
        "    inicio_epoch = time.process_time()\n",
        "    for images, labels in train_loader:\n",
        "        # Transformamos imagenes a vectores \n",
        "        images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "        # Pasada forward\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculamos la pérdida\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        # Hacemos la pasada backward\n",
        "        # Esto rellena el atributo .grad de todos los parametros\n",
        "        loss.backward()\n",
        "\n",
        "        # Hacemos un paso en el algoritmo de optimizacion\n",
        "        optimizer.step()\n",
        "\n",
        "        # Inicializamos los gradientes de los parametros a 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    tiempo_epochs += time.process_time() - inicio_epoch\n",
        "    ###############################\n",
        "    # calculamos la precision sobre el conjunto de testeo        \n",
        "    accuracy = calculateAccuracy(model, test_loader)\n",
        "    \n",
        "\n",
        "    # Reporte\n",
        "    #print('Epoch: {}. Loss: {}'.format(epoch, loss.item()))\n",
        "    print('Epoch: {}. Loss: {}. Accuracy: {}'.format(epoch, loss.item(), accuracy))\n",
        "\n",
        "print('Total time: {}'.format(tiempo_epochs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Accuracy: 8.1899995803833\n",
            "Epoch: 0. Loss: 0.4203987419605255. Accuracy: 89.22000122070312\n",
            "Epoch: 1. Loss: 0.19810040295124054. Accuracy: 90.93000030517578\n",
            "Epoch: 2. Loss: 0.25252336263656616. Accuracy: 91.91999816894531\n",
            "Epoch: 3. Loss: 0.5371927618980408. Accuracy: 92.47000122070312\n",
            "Epoch: 4. Loss: 0.2549794018268585. Accuracy: 93.05999755859375\n",
            "Epoch: 5. Loss: 0.2242819219827652. Accuracy: 93.38999938964844\n",
            "Epoch: 6. Loss: 0.1658615618944168. Accuracy: 93.88999938964844\n",
            "Epoch: 7. Loss: 0.11949853599071503. Accuracy: 94.02999877929688\n",
            "Epoch: 8. Loss: 0.04738394543528557. Accuracy: 94.58999633789062\n",
            "Epoch: 9. Loss: 0.12689921259880066. Accuracy: 94.79000091552734\n",
            "Total time: 77.47349037500015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6pnIJlYRlpi"
      },
      "source": [
        "Se entrena y prueba el modelo con descenso estocástico por gradiente simple, tasa de aprendizaje de 0.01 y dimensión de la capa oculta igual a 500."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6YNB36vEuDF",
        "outputId": "6d9390f2-eb62-4394-960a-6be5a3fd3b08"
      },
      "source": [
        "#Entrenamiento y prueba de la red con el dataset MNIST\n",
        "\n",
        "#Código para cargar los datos\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor())\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "batch_size = 32  # No cambiar tamaño del batch\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "########################################\n",
        "# Construimos la red\n",
        "# Las dimensiones de entrada y salida corresponden al dataset MNIST\n",
        "\n",
        "input_dim = 28*28\n",
        "hidden_dim = 500\n",
        "output_dim = 10\n",
        "\n",
        "model = FFNN_1HL(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "###############################\n",
        "# Definimos la funcion de perdida, en este caso entropia cruzada\n",
        "# Ojo: esta funcion calcula softmax y luego la entropia cruzada vista en clases\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "###################\n",
        "#Definimos el algoritmo de optimizacion, en este caso stochastic gradient descent simple\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "## Utilizar otros optimizers cuando sea necesario\n",
        "\n",
        "####################\n",
        "# Entrenamos y testeamos la red. No es necesario cambiar este código.\n",
        "# Imprimimos la precision antes de comenzar, la precision y funcion de perdida despues de cada epoca,\n",
        "# y el tiempo total de entrenamiento\n",
        "\n",
        "num_epochs = 10  # No cambiar cantidad de epocas\n",
        "\n",
        "accuracy = calculateAccuracy(model, test_loader)\n",
        "print('Initial Accuracy: {}'.format(accuracy))\n",
        "\n",
        "tiempo_epochs = 0\n",
        "for epoch in range(num_epochs):\n",
        "    inicio_epoch = time.process_time()\n",
        "    for images, labels in train_loader:\n",
        "        # Transformamos imagenes a vectores \n",
        "        images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "        # Pasada forward\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculamos la pérdida\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        # Hacemos la pasada backward\n",
        "        # Esto rellena el atributo .grad de todos los parametros\n",
        "        loss.backward()\n",
        "\n",
        "        # Hacemos un paso en el algoritmo de optimizacion\n",
        "        optimizer.step()\n",
        "\n",
        "        # Inicializamos los gradientes de los parametros a 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    tiempo_epochs += time.process_time() - inicio_epoch\n",
        "    ###############################\n",
        "    # calculamos la precision sobre el conjunto de testeo        \n",
        "    accuracy = calculateAccuracy(model, test_loader)\n",
        "    \n",
        "\n",
        "    # Reporte\n",
        "    #print('Epoch: {}. Loss: {}'.format(epoch, loss.item()))\n",
        "    print('Epoch: {}. Loss: {}. Accuracy: {}'.format(epoch, loss.item(), accuracy))\n",
        "\n",
        "print('Total time: {}'.format(tiempo_epochs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Accuracy: 9.5\n",
            "Epoch: 0. Loss: 0.5301414132118225. Accuracy: 89.45999908447266\n",
            "Epoch: 1. Loss: 0.31317245960235596. Accuracy: 90.94000244140625\n",
            "Epoch: 2. Loss: 0.23662233352661133. Accuracy: 92.12999725341797\n",
            "Epoch: 3. Loss: 0.3042011857032776. Accuracy: 92.7699966430664\n",
            "Epoch: 4. Loss: 0.1294451653957367. Accuracy: 93.22000122070312\n",
            "Epoch: 5. Loss: 0.1885395050048828. Accuracy: 93.7699966430664\n",
            "Epoch: 6. Loss: 0.28076866269111633. Accuracy: 94.08999633789062\n",
            "Epoch: 7. Loss: 0.14509224891662598. Accuracy: 94.5199966430664\n",
            "Epoch: 8. Loss: 0.07743940502405167. Accuracy: 94.69999694824219\n",
            "Epoch: 9. Loss: 0.16754432022571564. Accuracy: 95.05000305175781\n",
            "Total time: 104.65108874200007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdkdtQGuR2pY"
      },
      "source": [
        "Se entrena y prueba el modelo con descenso estocástico por gradiente simple, tasa de aprendizaje de 0.1 y dimensión de la capa oculta igual a 500."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Fn1IRL0GF9E",
        "outputId": "69ab885a-7beb-490c-9dd9-fb9c943055e8"
      },
      "source": [
        "#Entrenamiento y prueba de la red con el dataset MNIST\n",
        "\n",
        "#Código para cargar los datos\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor())\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "batch_size = 32  # No cambiar tamaño del batch\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "########################################\n",
        "# Construimos la red\n",
        "# Las dimensiones de entrada y salida corresponden al dataset MNIST\n",
        "\n",
        "input_dim = 28*28\n",
        "hidden_dim = 500\n",
        "output_dim = 10\n",
        "\n",
        "model = FFNN_1HL(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "###############################\n",
        "# Definimos la funcion de perdida, en este caso entropia cruzada\n",
        "# Ojo: esta funcion calcula softmax y luego la entropia cruzada vista en clases\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "###################\n",
        "#Definimos el algoritmo de optimizacion, en este caso stochastic gradient descent simple\n",
        "\n",
        "learning_rate = 0.1\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "## Utilizar otros optimizers cuando sea necesario\n",
        "\n",
        "####################\n",
        "# Entrenamos y testeamos la red. No es necesario cambiar este código.\n",
        "# Imprimimos la precision antes de comenzar, la precision y funcion de perdida despues de cada epoca,\n",
        "# y el tiempo total de entrenamiento\n",
        "\n",
        "num_epochs = 10  # No cambiar cantidad de epocas\n",
        "\n",
        "accuracy = calculateAccuracy(model, test_loader)\n",
        "print('Initial Accuracy: {}'.format(accuracy))\n",
        "\n",
        "tiempo_epochs = 0\n",
        "for epoch in range(num_epochs):\n",
        "    inicio_epoch = time.process_time()\n",
        "    for images, labels in train_loader:\n",
        "        # Transformamos imagenes a vectores \n",
        "        images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "        # Pasada forward\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculamos la pérdida\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        # Hacemos la pasada backward\n",
        "        # Esto rellena el atributo .grad de todos los parametros\n",
        "        loss.backward()\n",
        "\n",
        "        # Hacemos un paso en el algoritmo de optimizacion\n",
        "        optimizer.step()\n",
        "\n",
        "        # Inicializamos los gradientes de los parametros a 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    tiempo_epochs += time.process_time() - inicio_epoch\n",
        "    ###############################\n",
        "    # calculamos la precision sobre el conjunto de testeo        \n",
        "    accuracy = calculateAccuracy(model, test_loader)\n",
        "    \n",
        "\n",
        "    # Reporte\n",
        "    #print('Epoch: {}. Loss: {}'.format(epoch, loss.item()))\n",
        "    print('Epoch: {}. Loss: {}. Accuracy: {}'.format(epoch, loss.item(), accuracy))\n",
        "\n",
        "print('Total time: {}'.format(tiempo_epochs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Accuracy: 6.539999961853027\n",
            "Epoch: 0. Loss: 0.1672700047492981. Accuracy: 95.12999725341797\n",
            "Epoch: 1. Loss: 0.36417534947395325. Accuracy: 96.77999877929688\n",
            "Epoch: 2. Loss: 0.06076236814260483. Accuracy: 97.33000183105469\n",
            "Epoch: 3. Loss: 0.06613995134830475. Accuracy: 97.20999908447266\n",
            "Epoch: 4. Loss: 0.07893387228250504. Accuracy: 97.72000122070312\n",
            "Epoch: 5. Loss: 0.0106982896104455. Accuracy: 97.93000030517578\n",
            "Epoch: 6. Loss: 0.13810506463050842. Accuracy: 97.88999938964844\n",
            "Epoch: 7. Loss: 0.01612047292292118. Accuracy: 97.83999633789062\n",
            "Epoch: 8. Loss: 0.0020970746409147978. Accuracy: 97.94999694824219\n",
            "Epoch: 9. Loss: 0.0035078502260148525. Accuracy: 98.16000366210938\n",
            "Total time: 102.90320013399992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mId5Z_5fR9wq"
      },
      "source": [
        "Se entrena y prueba el modelo con descenso estocástico por gradiente simple, tasa de aprendizaje de 0.001 y dimensión de la capa oculta igual a 500."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNbFLuAZGjOi",
        "outputId": "649467ed-baa1-4f42-d81d-258bd2b2daca"
      },
      "source": [
        "#Entrenamiento y prueba de la red con el dataset MNIST\n",
        "\n",
        "#Código para cargar los datos\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor())\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "batch_size = 32  # No cambiar tamaño del batch\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "########################################\n",
        "# Construimos la red\n",
        "# Las dimensiones de entrada y salida corresponden al dataset MNIST\n",
        "\n",
        "input_dim = 28*28\n",
        "hidden_dim = 500\n",
        "output_dim = 10\n",
        "\n",
        "model = FFNN_1HL(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "###############################\n",
        "# Definimos la funcion de perdida, en este caso entropia cruzada\n",
        "# Ojo: esta funcion calcula softmax y luego la entropia cruzada vista en clases\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "###################\n",
        "#Definimos el algoritmo de optimizacion, en este caso stochastic gradient descent simple\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "## Utilizar otros optimizers cuando sea necesario\n",
        "\n",
        "####################\n",
        "# Entrenamos y testeamos la red. No es necesario cambiar este código.\n",
        "# Imprimimos la precision antes de comenzar, la precision y funcion de perdida despues de cada epoca,\n",
        "# y el tiempo total de entrenamiento\n",
        "\n",
        "num_epochs = 10  # No cambiar cantidad de epocas\n",
        "\n",
        "accuracy = calculateAccuracy(model, test_loader)\n",
        "print('Initial Accuracy: {}'.format(accuracy))\n",
        "\n",
        "tiempo_epochs = 0\n",
        "for epoch in range(num_epochs):\n",
        "    inicio_epoch = time.process_time()\n",
        "    for images, labels in train_loader:\n",
        "        # Transformamos imagenes a vectores \n",
        "        images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "        # Pasada forward\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculamos la pérdida\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        # Hacemos la pasada backward\n",
        "        # Esto rellena el atributo .grad de todos los parametros\n",
        "        loss.backward()\n",
        "\n",
        "        # Hacemos un paso en el algoritmo de optimizacion\n",
        "        optimizer.step()\n",
        "\n",
        "        # Inicializamos los gradientes de los parametros a 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    tiempo_epochs += time.process_time() - inicio_epoch\n",
        "    ###############################\n",
        "    # calculamos la precision sobre el conjunto de testeo        \n",
        "    accuracy = calculateAccuracy(model, test_loader)\n",
        "    \n",
        "\n",
        "    # Reporte\n",
        "    #print('Epoch: {}. Loss: {}'.format(epoch, loss.item()))\n",
        "    print('Epoch: {}. Loss: {}. Accuracy: {}'.format(epoch, loss.item(), accuracy))\n",
        "\n",
        "print('Total time: {}'.format(tiempo_epochs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Accuracy: 17.40999984741211\n",
            "Epoch: 0. Loss: 1.798116683959961. Accuracy: 74.5\n",
            "Epoch: 1. Loss: 1.1157560348510742. Accuracy: 80.97000122070312\n",
            "Epoch: 2. Loss: 0.8444420099258423. Accuracy: 83.91999816894531\n",
            "Epoch: 3. Loss: 0.7269243597984314. Accuracy: 86.02999877929688\n",
            "Epoch: 4. Loss: 0.44353482127189636. Accuracy: 87.0\n",
            "Epoch: 5. Loss: 0.3937283754348755. Accuracy: 87.7699966430664\n",
            "Epoch: 6. Loss: 0.4958999752998352. Accuracy: 88.51000213623047\n",
            "Epoch: 7. Loss: 0.5088504552841187. Accuracy: 89.02999877929688\n",
            "Epoch: 8. Loss: 0.41216573119163513. Accuracy: 89.33999633789062\n",
            "Epoch: 9. Loss: 0.6187611222267151. Accuracy: 89.66000366210938\n",
            "Total time: 103.15777044599974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMHPd65bSAHZ"
      },
      "source": [
        "Se entrena y prueba el modelo con descenso estocástico por gradiente simple, tasa de aprendizaje de 0.0001 y dimensión de la capa oculta igual a 500."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaQerJv4GqkB",
        "outputId": "45da46d1-72c7-4887-ea02-b30863405b33"
      },
      "source": [
        "#Entrenamiento y prueba de la red con el dataset MNIST\n",
        "\n",
        "#Código para cargar los datos\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor())\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "batch_size = 32  # No cambiar tamaño del batch\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "########################################\n",
        "# Construimos la red\n",
        "# Las dimensiones de entrada y salida corresponden al dataset MNIST\n",
        "\n",
        "input_dim = 28*28\n",
        "hidden_dim = 500\n",
        "output_dim = 10\n",
        "\n",
        "model = FFNN_1HL(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "###############################\n",
        "# Definimos la funcion de perdida, en este caso entropia cruzada\n",
        "# Ojo: esta funcion calcula softmax y luego la entropia cruzada vista en clases\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "###################\n",
        "#Definimos el algoritmo de optimizacion, en este caso stochastic gradient descent simple\n",
        "\n",
        "learning_rate = 0.0001\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "## Utilizar otros optimizers cuando sea necesario\n",
        "\n",
        "####################\n",
        "# Entrenamos y testeamos la red. No es necesario cambiar este código.\n",
        "# Imprimimos la precision antes de comenzar, la precision y funcion de perdida despues de cada epoca,\n",
        "# y el tiempo total de entrenamiento\n",
        "\n",
        "num_epochs = 10  # No cambiar cantidad de epocas\n",
        "\n",
        "accuracy = calculateAccuracy(model, test_loader)\n",
        "print('Initial Accuracy: {}'.format(accuracy))\n",
        "\n",
        "tiempo_epochs = 0\n",
        "for epoch in range(num_epochs):\n",
        "    inicio_epoch = time.process_time()\n",
        "    for images, labels in train_loader:\n",
        "        # Transformamos imagenes a vectores \n",
        "        images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "        # Pasada forward\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculamos la pérdida\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        # Hacemos la pasada backward\n",
        "        # Esto rellena el atributo .grad de todos los parametros\n",
        "        loss.backward()\n",
        "\n",
        "        # Hacemos un paso en el algoritmo de optimizacion\n",
        "        optimizer.step()\n",
        "\n",
        "        # Inicializamos los gradientes de los parametros a 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    tiempo_epochs += time.process_time() - inicio_epoch\n",
        "    ###############################\n",
        "    # calculamos la precision sobre el conjunto de testeo        \n",
        "    accuracy = calculateAccuracy(model, test_loader)\n",
        "    \n",
        "\n",
        "    # Reporte\n",
        "    #print('Epoch: {}. Loss: {}'.format(epoch, loss.item()))\n",
        "    print('Epoch: {}. Loss: {}. Accuracy: {}'.format(epoch, loss.item(), accuracy))\n",
        "\n",
        "print('Total time: {}'.format(tiempo_epochs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Accuracy: 8.470000267028809\n",
            "Epoch: 0. Loss: 2.2619192600250244. Accuracy: 23.950000762939453\n",
            "Epoch: 1. Loss: 2.22544002532959. Accuracy: 39.119998931884766\n",
            "Epoch: 2. Loss: 2.1842217445373535. Accuracy: 50.9900016784668\n",
            "Epoch: 3. Loss: 2.086149215698242. Accuracy: 60.290000915527344\n",
            "Epoch: 4. Loss: 2.1034886837005615. Accuracy: 65.33999633789062\n",
            "Epoch: 5. Loss: 2.077972650527954. Accuracy: 68.33000183105469\n",
            "Epoch: 6. Loss: 1.9368476867675781. Accuracy: 70.26000213623047\n",
            "Epoch: 7. Loss: 1.836832880973816. Accuracy: 71.48999786376953\n",
            "Epoch: 8. Loss: 1.7858805656433105. Accuracy: 72.69000244140625\n",
            "Epoch: 9. Loss: 1.8039236068725586. Accuracy: 73.66000366210938\n",
            "Total time: 109.02275252200025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKo177NHSEXN"
      },
      "source": [
        "Se cambia la clase creada anteriormente y se cambia la funcion de activación a la función Sigmoid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWglXBJEH-Ao"
      },
      "source": [
        "# Aca debe implementar la clase FFNN_1HL para una red Feed-Forward, con una capa escondida\n",
        "class FFNN_1HL(torch.nn.Module):   \n",
        "  def __init__(self, input_dim, hidden1_dim, output_dim): #definir el constructor\n",
        "    super(FFNN_1HL, self).__init__()\n",
        "    self.fc1 = torch.nn.Linear(input_dim, hidden1_dim, bias=True) #inicializa capa de entrada y la capa oculta\n",
        "    self.act1 = torch.nn.Sigmoid()\n",
        "    self.fc2 = torch.nn.Linear(hidden1_dim, output_dim, bias=True)\n",
        "\n",
        "  def forward(self, x): #definir funcion forward\n",
        "        \n",
        "    z1 = self.fc1(x)\n",
        "    h1 = self.act1(z1)\n",
        "    z = self.fc2(h1) # No aplicamos softmax, ya que la funcion torch.nn.CrossEntropyLoss() la aplica\n",
        "      \n",
        "    return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY5TW2TXSe_X"
      },
      "source": [
        "Se entrena y prueba el modelo con descenso estocástico por gradiente simple, función de activación Sigmoid, tasa de aprendizaje de 0.01 y dimensión de la capa oculta igual a 500."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtgEALj-HMYE",
        "outputId": "35c3a1cb-3b0c-48db-9a25-de64589627b2"
      },
      "source": [
        "#Entrenamiento y prueba de la red con el dataset MNIST\n",
        "\n",
        "#Código para cargar los datos\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor())\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "batch_size = 32  # No cambiar tamaño del batch\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "########################################\n",
        "# Construimos la red\n",
        "# Las dimensiones de entrada y salida corresponden al dataset MNIST\n",
        "\n",
        "input_dim = 28*28\n",
        "hidden_dim = 500\n",
        "output_dim = 10\n",
        "\n",
        "model = FFNN_1HL(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "###############################\n",
        "# Definimos la funcion de perdida, en este caso entropia cruzada\n",
        "# Ojo: esta funcion calcula softmax y luego la entropia cruzada vista en clases\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "###################\n",
        "#Definimos el algoritmo de optimizacion, en este caso stochastic gradient descent simple\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "## Utilizar otros optimizers cuando sea necesario\n",
        "\n",
        "####################\n",
        "# Entrenamos y testeamos la red. No es necesario cambiar este código.\n",
        "# Imprimimos la precision antes de comenzar, la precision y funcion de perdida despues de cada epoca,\n",
        "# y el tiempo total de entrenamiento\n",
        "\n",
        "num_epochs = 10  # No cambiar cantidad de epocas\n",
        "\n",
        "accuracy = calculateAccuracy(model, test_loader)\n",
        "print('Initial Accuracy: {}'.format(accuracy))\n",
        "\n",
        "tiempo_epochs = 0\n",
        "for epoch in range(num_epochs):\n",
        "    inicio_epoch = time.process_time()\n",
        "    for images, labels in train_loader:\n",
        "        # Transformamos imagenes a vectores \n",
        "        images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "        # Pasada forward\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculamos la pérdida\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        # Hacemos la pasada backward\n",
        "        # Esto rellena el atributo .grad de todos los parametros\n",
        "        loss.backward()\n",
        "\n",
        "        # Hacemos un paso en el algoritmo de optimizacion\n",
        "        optimizer.step()\n",
        "\n",
        "        # Inicializamos los gradientes de los parametros a 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    tiempo_epochs += time.process_time() - inicio_epoch\n",
        "    ###############################\n",
        "    # calculamos la precision sobre el conjunto de testeo        \n",
        "    accuracy = calculateAccuracy(model, test_loader)\n",
        "    \n",
        "\n",
        "    # Reporte\n",
        "    #print('Epoch: {}. Loss: {}'.format(epoch, loss.item()))\n",
        "    print('Epoch: {}. Loss: {}. Accuracy: {}'.format(epoch, loss.item(), accuracy))\n",
        "\n",
        "print('Total time: {}'.format(tiempo_epochs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Accuracy: 10.279999732971191\n",
            "Epoch: 0. Loss: 0.9872061610221863. Accuracy: 75.31999969482422\n",
            "Epoch: 1. Loss: 0.6582845449447632. Accuracy: 85.47000122070312\n",
            "Epoch: 2. Loss: 0.33700230717658997. Accuracy: 87.66999816894531\n",
            "Epoch: 3. Loss: 0.4269200563430786. Accuracy: 88.79000091552734\n",
            "Epoch: 4. Loss: 0.2938231825828552. Accuracy: 89.5\n",
            "Epoch: 5. Loss: 0.4196559488773346. Accuracy: 89.80999755859375\n",
            "Epoch: 6. Loss: 0.43551790714263916. Accuracy: 90.16000366210938\n",
            "Epoch: 7. Loss: 0.32238149642944336. Accuracy: 90.41000366210938\n",
            "Epoch: 8. Loss: 0.5195304751396179. Accuracy: 90.62000274658203\n",
            "Epoch: 9. Loss: 0.33514270186424255. Accuracy: 90.94000244140625\n",
            "Total time: 105.62819426600004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWqu1nCcSgsW"
      },
      "source": [
        "Se cambia la clase creada anteriormente y se cambia la funcion de activación a la función Tanh."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCKCbtBHIFs9"
      },
      "source": [
        "# Aca debe implementar la clase FFNN_1HL para una red Feed-Forward, con una capa escondida\n",
        "class FFNN_1HL(torch.nn.Module):   \n",
        "  def __init__(self, input_dim, hidden1_dim, output_dim): #definir el constructor\n",
        "    super(FFNN_1HL, self).__init__()\n",
        "    self.fc1 = torch.nn.Linear(input_dim, hidden1_dim, bias=True) #inicializa capa de entrada y la capa oculta\n",
        "    self.act1 = torch.nn.Tanh()\n",
        "    self.fc2 = torch.nn.Linear(hidden1_dim, output_dim, bias=True)\n",
        "\n",
        "  def forward(self, x): #definir funcion forward\n",
        "        \n",
        "    z1 = self.fc1(x)\n",
        "    h1 = self.act1(z1)\n",
        "    z = self.fc2(h1) # No aplicamos softmax, ya que la funcion torch.nn.CrossEntropyLoss() la aplica\n",
        "      \n",
        "    return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwSEMGTZSres"
      },
      "source": [
        "Se entrena y prueba el modelo con descenso estocástico por gradiente simple, función de activación Tanh, tasa de aprendizaje de 0.01 y dimensión de la capa oculta igual a 500."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TITTW-kjIjql",
        "outputId": "5806066d-0569-4550-da68-a83078c93867"
      },
      "source": [
        "#Entrenamiento y prueba de la red con el dataset MNIST\n",
        "\n",
        "#Código para cargar los datos\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor())\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "batch_size = 32  # No cambiar tamaño del batch\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "########################################\n",
        "# Construimos la red\n",
        "# Las dimensiones de entrada y salida corresponden al dataset MNIST\n",
        "\n",
        "input_dim = 28*28\n",
        "hidden_dim = 500\n",
        "output_dim = 10\n",
        "\n",
        "model = FFNN_1HL(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "###############################\n",
        "# Definimos la funcion de perdida, en este caso entropia cruzada\n",
        "# Ojo: esta funcion calcula softmax y luego la entropia cruzada vista en clases\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "###################\n",
        "#Definimos el algoritmo de optimizacion, en este caso stochastic gradient descent simple\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "## Utilizar otros optimizers cuando sea necesario\n",
        "\n",
        "####################\n",
        "# Entrenamos y testeamos la red. No es necesario cambiar este código.\n",
        "# Imprimimos la precision antes de comenzar, la precision y funcion de perdida despues de cada epoca,\n",
        "# y el tiempo total de entrenamiento\n",
        "\n",
        "num_epochs = 10  # No cambiar cantidad de epocas\n",
        "\n",
        "accuracy = calculateAccuracy(model, test_loader)\n",
        "print('Initial Accuracy: {}'.format(accuracy))\n",
        "\n",
        "tiempo_epochs = 0\n",
        "for epoch in range(num_epochs):\n",
        "    inicio_epoch = time.process_time()\n",
        "    for images, labels in train_loader:\n",
        "        # Transformamos imagenes a vectores \n",
        "        images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "        # Pasada forward\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculamos la pérdida\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        # Hacemos la pasada backward\n",
        "        # Esto rellena el atributo .grad de todos los parametros\n",
        "        loss.backward()\n",
        "\n",
        "        # Hacemos un paso en el algoritmo de optimizacion\n",
        "        optimizer.step()\n",
        "\n",
        "        # Inicializamos los gradientes de los parametros a 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    tiempo_epochs += time.process_time() - inicio_epoch\n",
        "    ###############################\n",
        "    # calculamos la precision sobre el conjunto de testeo        \n",
        "    accuracy = calculateAccuracy(model, test_loader)\n",
        "    \n",
        "\n",
        "    # Reporte\n",
        "    #print('Epoch: {}. Loss: {}'.format(epoch, loss.item()))\n",
        "    print('Epoch: {}. Loss: {}. Accuracy: {}'.format(epoch, loss.item(), accuracy))\n",
        "\n",
        "print('Total time: {}'.format(tiempo_epochs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Accuracy: 13.739999771118164\n",
            "Epoch: 0. Loss: 0.30576440691947937. Accuracy: 89.33000183105469\n",
            "Epoch: 1. Loss: 0.2785475254058838. Accuracy: 90.52999877929688\n",
            "Epoch: 2. Loss: 0.4172811806201935. Accuracy: 91.47000122070312\n",
            "Epoch: 3. Loss: 0.2340552657842636. Accuracy: 91.77999877929688\n",
            "Epoch: 4. Loss: 0.8662914037704468. Accuracy: 91.86000061035156\n",
            "Epoch: 5. Loss: 0.12896671891212463. Accuracy: 92.18000030517578\n",
            "Epoch: 6. Loss: 0.09679830819368362. Accuracy: 92.37000274658203\n",
            "Epoch: 7. Loss: 0.4532102346420288. Accuracy: 92.55000305175781\n",
            "Epoch: 8. Loss: 0.29645246267318726. Accuracy: 92.63999938964844\n",
            "Epoch: 9. Loss: 0.34726378321647644. Accuracy: 92.87999725341797\n",
            "Total time: 104.16227562999984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32XhCyziSwLm"
      },
      "source": [
        "Se vuelve a modificar la clase usando la funcion de activación ReLU para las últimas pruebas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT73vvSMJUJW"
      },
      "source": [
        "# Aca debe implementar la clase FFNN_1HL para una red Feed-Forward, con una capa escondida\n",
        "class FFNN_1HL(torch.nn.Module):   \n",
        "  def __init__(self, input_dim, hidden1_dim, output_dim): #definir el constructor\n",
        "    super(FFNN_1HL, self).__init__()\n",
        "    self.fc1 = torch.nn.Linear(input_dim, hidden1_dim, bias=True) #inicializa capa de entrada y la capa oculta\n",
        "    self.act1 = torch.nn.ReLU()\n",
        "    self.fc2 = torch.nn.Linear(hidden1_dim, output_dim, bias=True)\n",
        "\n",
        "  def forward(self, x): #definir funcion forward\n",
        "        \n",
        "    z1 = self.fc1(x)\n",
        "    h1 = self.act1(z1)\n",
        "    z = self.fc2(h1) # No aplicamos softmax, ya que la funcion torch.nn.CrossEntropyLoss() la aplica\n",
        "      \n",
        "    return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsyLf9epVVo_"
      },
      "source": [
        "Se entrena y prueba el modelo con descenso estocástico por gradiente con momentum de 0.9, función de activación ReLU, tasa de aprendizaje de 0.01 y dimensión de la capa oculta igual a 500."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q23O-Lq4JdVj",
        "outputId": "290f829c-b956-4b31-f162-5babcc8701d1"
      },
      "source": [
        "#Entrenamiento y prueba de la red con el dataset MNIST\n",
        "\n",
        "#Código para cargar los datos\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor())\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "batch_size = 32  # No cambiar tamaño del batch\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "########################################\n",
        "# Construimos la red\n",
        "# Las dimensiones de entrada y salida corresponden al dataset MNIST\n",
        "\n",
        "input_dim = 28*28\n",
        "hidden_dim = 500\n",
        "output_dim = 10\n",
        "\n",
        "model = FFNN_1HL(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "###############################\n",
        "# Definimos la funcion de perdida, en este caso entropia cruzada\n",
        "# Ojo: esta funcion calcula softmax y luego la entropia cruzada vista en clases\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "###################\n",
        "#Definimos el algoritmo de optimizacion, en este caso stochastic gradient descent simple\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "## Utilizar otros optimizers cuando sea necesario\n",
        "\n",
        "####################\n",
        "# Entrenamos y testeamos la red. No es necesario cambiar este código.\n",
        "# Imprimimos la precision antes de comenzar, la precision y funcion de perdida despues de cada epoca,\n",
        "# y el tiempo total de entrenamiento\n",
        "\n",
        "num_epochs = 10  # No cambiar cantidad de epocas\n",
        "\n",
        "accuracy = calculateAccuracy(model, test_loader)\n",
        "print('Initial Accuracy: {}'.format(accuracy))\n",
        "\n",
        "tiempo_epochs = 0\n",
        "for epoch in range(num_epochs):\n",
        "    inicio_epoch = time.process_time()\n",
        "    for images, labels in train_loader:\n",
        "        # Transformamos imagenes a vectores \n",
        "        images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "        # Pasada forward\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculamos la pérdida\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        # Hacemos la pasada backward\n",
        "        # Esto rellena el atributo .grad de todos los parametros\n",
        "        loss.backward()\n",
        "\n",
        "        # Hacemos un paso en el algoritmo de optimizacion\n",
        "        optimizer.step()\n",
        "\n",
        "        # Inicializamos los gradientes de los parametros a 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    tiempo_epochs += time.process_time() - inicio_epoch\n",
        "    ###############################\n",
        "    # calculamos la precision sobre el conjunto de testeo        \n",
        "    accuracy = calculateAccuracy(model, test_loader)\n",
        "    \n",
        "\n",
        "    # Reporte\n",
        "    #print('Epoch: {}. Loss: {}'.format(epoch, loss.item()))\n",
        "    print('Epoch: {}. Loss: {}. Accuracy: {}'.format(epoch, loss.item(), accuracy))\n",
        "\n",
        "print('Total time: {}'.format(tiempo_epochs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Accuracy: 15.069999694824219\n",
            "Epoch: 0. Loss: 0.20808057487010956. Accuracy: 94.69000244140625\n",
            "Epoch: 1. Loss: 0.04528999328613281. Accuracy: 96.68000030517578\n",
            "Epoch: 2. Loss: 0.0725172758102417. Accuracy: 97.0199966430664\n",
            "Epoch: 3. Loss: 0.09029022604227066. Accuracy: 97.58000183105469\n",
            "Epoch: 4. Loss: 0.007448678836226463. Accuracy: 97.58999633789062\n",
            "Epoch: 5. Loss: 0.037819668650627136. Accuracy: 97.94999694824219\n",
            "Epoch: 6. Loss: 0.01138770766556263. Accuracy: 97.81999969482422\n",
            "Epoch: 7. Loss: 0.005334752611815929. Accuracy: 98.02999877929688\n",
            "Epoch: 8. Loss: 0.05759888142347336. Accuracy: 97.75\n",
            "Epoch: 9. Loss: 0.011603009887039661. Accuracy: 98.08999633789062\n",
            "Total time: 143.82335730600016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRFs09gfVkML"
      },
      "source": [
        "Se entrena y prueba el modelo con optimizador Adam con parámetros por defecto de pytorch, función de activación ReLU, tasa de aprendizaje de 0.01 y dimensión de la capa oculta igual a 500."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMCvfypXKg0K",
        "outputId": "d34e792c-2b44-4d92-c3da-5f7be996e017"
      },
      "source": [
        "#Entrenamiento y prueba de la red con el dataset MNIST\n",
        "\n",
        "#Código para cargar los datos\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor())\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "batch_size = 32  # No cambiar tamaño del batch\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "########################################\n",
        "# Construimos la red\n",
        "# Las dimensiones de entrada y salida corresponden al dataset MNIST\n",
        "\n",
        "input_dim = 28*28\n",
        "hidden_dim = 500\n",
        "output_dim = 10\n",
        "\n",
        "model = FFNN_1HL(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "###############################\n",
        "# Definimos la funcion de perdida, en este caso entropia cruzada\n",
        "# Ojo: esta funcion calcula softmax y luego la entropia cruzada vista en clases\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "###################\n",
        "#Definimos el algoritmo de optimizacion, en este caso stochastic gradient descent simple\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "\n",
        "## Utilizar otros optimizers cuando sea necesario\n",
        "\n",
        "####################\n",
        "# Entrenamos y testeamos la red. No es necesario cambiar este código.\n",
        "# Imprimimos la precision antes de comenzar, la precision y funcion de perdida despues de cada epoca,\n",
        "# y el tiempo total de entrenamiento\n",
        "\n",
        "num_epochs = 10  # No cambiar cantidad de epocas\n",
        "\n",
        "accuracy = calculateAccuracy(model, test_loader)\n",
        "print('Initial Accuracy: {}'.format(accuracy))\n",
        "\n",
        "tiempo_epochs = 0\n",
        "for epoch in range(num_epochs):\n",
        "    inicio_epoch = time.process_time()\n",
        "    for images, labels in train_loader:\n",
        "        # Transformamos imagenes a vectores \n",
        "        images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "        # Pasada forward\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculamos la pérdida\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        # Hacemos la pasada backward\n",
        "        # Esto rellena el atributo .grad de todos los parametros\n",
        "        loss.backward()\n",
        "\n",
        "        # Hacemos un paso en el algoritmo de optimizacion\n",
        "        optimizer.step()\n",
        "\n",
        "        # Inicializamos los gradientes de los parametros a 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    tiempo_epochs += time.process_time() - inicio_epoch\n",
        "    ###############################\n",
        "    # calculamos la precision sobre el conjunto de testeo        \n",
        "    accuracy = calculateAccuracy(model, test_loader)\n",
        "    \n",
        "\n",
        "    # Reporte\n",
        "    #print('Epoch: {}. Loss: {}'.format(epoch, loss.item()))\n",
        "    print('Epoch: {}. Loss: {}. Accuracy: {}'.format(epoch, loss.item(), accuracy))\n",
        "\n",
        "print('Total time: {}'.format(tiempo_epochs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Accuracy: 12.020000457763672\n",
            "Epoch: 0. Loss: 0.11498289555311203. Accuracy: 97.0999984741211\n",
            "Epoch: 1. Loss: 0.04495486244559288. Accuracy: 97.63999938964844\n",
            "Epoch: 2. Loss: 0.07702187448740005. Accuracy: 97.55999755859375\n",
            "Epoch: 3. Loss: 0.00246690702624619. Accuracy: 97.66000366210938\n",
            "Epoch: 4. Loss: 0.07088015973567963. Accuracy: 97.98999786376953\n",
            "Epoch: 5. Loss: 0.0019395618000999093. Accuracy: 98.06999969482422\n",
            "Epoch: 6. Loss: 0.0010765620972961187. Accuracy: 97.69999694824219\n",
            "Epoch: 7. Loss: 0.038723934441804886. Accuracy: 98.0199966430664\n",
            "Epoch: 8. Loss: 0.033348117023706436. Accuracy: 98.19000244140625\n",
            "Epoch: 9. Loss: 0.04845401272177696. Accuracy: 97.91000366210938\n",
            "Total time: 215.92573409700026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_fawlaWVwi2"
      },
      "source": [
        "En este código se muestran todas las salidas de cada ejecución. El análisis de los datos del tiempo de ejecución, función de pérdida y la precisión de la red están descritos en el informe entregado en formato pdf."
      ]
    }
  ]
}